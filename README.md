# ğŸ§  DLMDSPWP01 â€“ Programming with Python  
### Advanced Data Processing & Visualization Project

---

## ğŸ“˜ Overview

This project is part of the **IU Internationale Hochschule** module  
**DLMDSPWP01 â€“ Programming with Python**.

It demonstrates **Object-Oriented Programming (OOP)** principles in Python applied to a real-world data analysis pipeline using:
- ğŸ§® **Pandas** & **NumPy** for data manipulation  
- ğŸ“Š **Matplotlib** & **Seaborn** for visualizations  
- ğŸ’¾ **SQLite** & **SQLAlchemy** for database operations  

The program:
1. Loads and normalizes **training**, **ideal**, and **test** datasets  
2. Finds the **best-fit ideal functions** for each training function  
3. Classifies **test data** points based on deviation criteria  
4. Generates **10 types of plots** for visualization  
5. Saves all processed results into an **SQLite database**

---

## ğŸ—ï¸ Project Structure

---

```text
DLMDSPWP01_PythonProject/
â”‚
â”œâ”€â”€ data/                              # Folder containing raw and reference datasets
â”‚   â”œâ”€â”€ train.csv                      # Training dataset (used to fit the model or logic)
â”‚   â”œâ”€â”€ ideal.csv                      # Ideal function data (used for comparison or mapping)
â”‚   â”œâ”€â”€ test.csv                       # Test dataset (used for evaluation or validation)
â”‚
â”œâ”€â”€ db/                                # Folder for database storage
â”‚   â””â”€â”€ database.db                    # SQLite database file (used for caching or persistence)
â”‚
â”œâ”€â”€ src/                               # All source code and logic modules
â”‚   â”œâ”€â”€ __init__.py                    # Marks 'src' as a Python package
â”‚   â”‚
â”‚   â”œâ”€â”€ base_processor.py              # Base class defining core data processing methods
â”‚   â”‚                                  # e.g., loading CSV, saving/loading from DB, normalization
â”‚   â”‚                                  # Common methods shared by multiple processors
â”‚   â”‚
â”‚   â”œâ”€â”€ derived_processor.py           # Derived class inheriting from base_processor.py
â”‚   â”‚                                  # Implements specific processing logic for the project
â”‚   â”‚                                  # e.g., function matching, error calculation, visualization
â”‚   â”‚
â”‚   â”œâ”€â”€ utils.py                       # Utility/helper functions (optional)
â”‚                                      # e.g., logging setup, config readers, or reusable snippets
â”‚
â”œâ”€â”€ notebooks/                         # Optional folder for Jupyter notebooks (EDA or testing)
â”‚   â””â”€â”€ exploration.ipynb              # Exploratory Data Analysis and preliminary visualizations
â”‚                                      # Used for understanding dataset patterns before coding
â”‚
â”œâ”€â”€ tests/                             # Unit tests ensuring correctness and stability of code
â”‚   â”œâ”€â”€ __init__.py                    # Marks the tests folder as a Python package
â”‚   â””â”€â”€ test_processing.py             # Unit tests for data processing logic
â”‚                                      # Uses pytest/unittest to validate processor methods
â”‚
â”œâ”€â”€ main.py                            # Main entry point of the project
â”‚                                      # Orchestrates the data pipeline:
â”‚                                      # 1. Loads data
â”‚                                      # 2. Processes it via DerivedDataProcessor
â”‚                                      # 3. Outputs results or saves to DB
â”‚
â”œâ”€â”€ requirements.txt                   # List of Python dependencies (for reproducibility)
â”‚                                      # e.g., pandas, numpy, matplotlib, seaborn, sqlalchemy
â”‚
â””â”€â”€ README.md                          # Project documentation file
                                       # Includes overview, setup instructions, and usage guide

## âš™ï¸ Installation & Setup Guide

### ğŸ§© 1. Clone the Repository
Open your terminal or PowerShell, navigate to your desired directory, and run:
```bash
git clone https://github.com/yourusername/DLMDSPWP01_PythonProject.git
cd DLMDSPWP01_PythonProject
ğŸ”¹ (If you havenâ€™t installed Git yet, download it from git-scm.com)

ğŸ§® 2. Create a Virtual Environment (Recommended)
Creating a virtual environment keeps your dependencies isolated from system Python.

ğŸªŸ On Windows:
bash
Copy code
python -m venv venv
venv\Scripts\activate
ğŸ On macOS / ğŸ§ Linux:
bash
Copy code
python3 -m venv venv
source venv/bin/activate
ğŸ“¦ 3. Install Required Packages
Once the virtual environment is activated:

bash
Copy code
pip install -r requirements.txt
If you donâ€™t have a requirements.txt yet, create one with:

nginx
Copy code
pandas
numpy
matplotlib
seaborn
sqlalchemy
ğŸ“‚ 4. Add Your Data Files
Make sure your train, ideal, and test CSV files are placed inside the /data folder:

kotlin
Copy code
data/
â”œâ”€â”€ train.csv
â”œâ”€â”€ ideal.csv
â””â”€â”€ test.csv
All files must contain:

a common X-column

one or more Y-columns (Y1, Y2, Y3, ...)

â–¶ï¸ Running the Program
Once everything is set up, simply run:

bash
Copy code
python main.py
âœ… The program will:

Load and normalize the datasets

Find best-fit ideal functions

Classify test data points

Generate and display plots

Save results into database.db

ğŸ“Š Output Example
X	Y (test)	No. of ideal func	Î”Y (test func)
1.23	2.45	Y12	0.067
2.13	1.09	Unassigned	0.532
...	...	...	...

ğŸ“ˆ Visualizations
The script generates 10 types of plots:

Line Plot â€“ Train vs Ideal

Scatter Plot â€“ Test vs Ideal

Residual Plot

Histogram

Boxplot

Bar Plot

Violin Plot

Area Plot

Combined Overlay Plot

Correlation Heatmap

All plots are shown interactively using Matplotlib and Seaborn.

ğŸ—ƒï¸ Database Output
The processed data is stored in database.db (SQLite) with these tables:

Table Name	Description
train_data	Normalized training data
ideal_data	Ideal function reference data
test_data	Test data used for classification
result	Final output with classifications & deviations

You can view it using any SQLite browser (e.g., DB Browser for SQLite).

ğŸ§® Classification Logic
For each test point:

Calculate deviation from every ideal function.

Select the minimum deviation.

deviationâ‰¤(max_train_deviationÃ—âˆš2)
assign that ideal function; otherwise mark as â€œUnassignedâ€.

ğŸ§  Learning Outcomes
This project demonstrates:

âœ… Class inheritance and modular code design (OOP)

âœ… Data normalization and transformation techniques

âœ… Database persistence with SQLAlchemy + SQLite

âœ… Advanced visualization using Matplotlib & Seaborn

âœ… Real-world data pipeline implementation in Python

ğŸ§© Troubleshooting
Issue	Cause	Solution
ModuleNotFoundError	Missing package	Run pip install -r requirements.txt
TypeError: cannot unpack NoneType	classify_test_data() not returning correctly	Ensure it returns labels, deviations
ValueError: Length mismatch	DataFrame size vs result list mismatch	Check that CSVs have same number of X-values
Plots not showing	Non-interactive terminal	Run inside VSCode, Jupyter, or enable %matplotlib inline

ğŸ‘¨â€ğŸ’» Author Information
Name: Haroon Nissar Haroon Nissar
Course: DLMDSPWP01 â€“ Programming with Python
University: IU Internationale Hochschule
Year: 2025
Language: Python 3.13#


